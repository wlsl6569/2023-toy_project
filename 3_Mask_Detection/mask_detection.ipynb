{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Rc693xV_s-9_"
   },
   "source": [
    "# 1. Labeling images for Object Detection\n",
    "\n",
    "* labelimg 패키지 이용하여 이미지 라벨링하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyAkBIIBs8Eq"
   },
   "outputs": [],
   "source": [
    "# 작업 폴더 설정 후 anaconda prompt에서 작업\n",
    "\n",
    "\n",
    "# 샘플 프로젝트 리포지토리와  복제\n",
    "git clone https://github.com/nicknochnack/RealTimeObjectDetection\n",
    "\n",
    "# 이미지 라벨을 지정하는 파이썬 패키지, 복제하여 RealTimeObjectDetection>Tensorflow 에 넣기\n",
    "git clone https://github.com/tzutalin/labelImg\n",
    "\n",
    "# labelimg 폴더로 이동 후 몇가지 종속성 설치 (https://wonderbout.tistory.com/185)\n",
    "\n",
    "pip install pyqt5-tools 윈도우 아나콘다 유저\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "#작업 폴더 설정 후 anaconda prompt에서 작업\n",
    "\n",
    "#< 샘플 프로젝트 clone>\n",
    "\n",
    "# 1.샘플 프로젝트 리포지토리와  복제\n",
    "git clone https://github.com/nicknochnack/RealTimeObjectDetection\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------\"\"\"\n",
    "#<imagelabel 설치>\n",
    "#이미지 라벨을 지정하는 파이썬 패키지, 복제하여 RealTimeObjectDetection>Tensorflow 에 넣기 \n",
    "git clone https://github.com/tzutalin/labelImg\n",
    "\n",
    "l#abelimg 폴더로 이동 후 두가지 종속성 설치 (https://wonderbout.tistory.com/185)\n",
    "\n",
    "#(1) pip install pyqt5-tools (윈도우 아나콘다 유저 경우) 혹은 conda install pyqt=5\n",
    "#(2) conda -c anaconda lxml resource.qrc 파일을 .py로 복제하여 라이브러리 폴더에 넣기(두개 다) prcc5 -o resources.py resources.qrc\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------\"\"\"\n",
    "#< 이미지 다운로드 받아서 workspace > images에 넣기>\n",
    "#https://www.kaggle.com/datasets/wobotintelligence/face-mask-detection-dataset\n",
    "\n",
    "#프롬프트에서 python labelImg.py 로 패키지 실행\n",
    "#(1) view - 자동 저장 켜주기\n",
    "#(2) 저장 폴더를 아까 이미지 모아둔 폴더로 바꿔주기\n",
    "\"\"\"----------------------------------------------------------------------------------------\"\"\"\n",
    "#python labelImg\n",
    "#(1) view에서 자동 저장 확인\n",
    "#(2) change save Dir 하여 아까 이미지 모아둔 폴더로 선택\n",
    "#(3) open Dir해서 사진 있는 폴더 선택\n",
    "\n",
    "#w : 라벨링 지정 툴\n",
    "#a / d : 이미지 넘기기\n",
    "\n",
    "\n",
    "#이 과정에서 labelImg 창이 닫힌다면 공식 labelImg git 페이지에 가서 설치 다시 해볼 것\n",
    "#(해결 : pip3 install labelImg\n",
    "# python labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE])\n",
    "\n",
    "#(4) w 눌러 사진들 입주변 드래그 해서 라벨링해준다  - 라벨링된 파일들이 경로에 생성\n",
    "#(5) 이제 교육과 테스트 용도로 분류하여 파일에 나눠 넣어준다 ( 원본 이미지와 함께) \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GXrEi3WxtLWX"
   },
   "source": [
    "# 2. Training Tensorflow SSD\n",
    "### tensorflow 객체 감지 API를 사용하여 딥 러닝 모델 훈련하기 \n",
    "* SSD MobileNet을 이용하여 전이 학습(transfer learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  -----------------------------generate_tfrecord를 tensor flow v2에 맞게 수정-------------------\n",
    "\n",
    "\"\"\" Sample TensorFlow XML-to-TFRecord converter\n",
    "\n",
    "usage: generate_tfrecord.py [-h] [-x XML_DIR] [-l LABELS_PATH] [-o OUTPUT_PATH] [-i IMAGE_DIR] [-c CSV_PATH]\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  -x XML_DIR, --xml_dir XML_DIR\n",
    "                        Path to the folder where the input .xml files are stored.\n",
    "  -l LABELS_PATH, --labels_path LABELS_PATH\n",
    "                        Path to the labels (.pbtxt) file.\n",
    "  -o OUTPUT_PATH, --output_path OUTPUT_PATH\n",
    "                        Path of output TFRecord (.record) file.\n",
    "  -i IMAGE_DIR, --image_dir IMAGE_DIR\n",
    "                        Path to the folder where the input image files are stored. Defaults to the same directory as XML_DIR.\n",
    "  -c CSV_PATH, --csv_path CSV_PATH\n",
    "                        Path of output .csv file. If none provided, then no file will be written.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import io\n",
    "import xml.etree.ElementTree as ET\n",
    "import argparse\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util, label_map_util\n",
    "from collections import namedtuple\n",
    "\n",
    "# Initiate argument parser\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Sample TensorFlow XML-to-TFRecord converter\")\n",
    "parser.add_argument(\"-x\",\n",
    "                    \"--xml_dir\",\n",
    "                    help=\"Path to the folder where the input .xml files are stored.\",\n",
    "                    type=str)\n",
    "parser.add_argument(\"-l\",\n",
    "                    \"--labels_path\",\n",
    "                    help=\"Path to the labels (.pbtxt) file.\", type=str)\n",
    "parser.add_argument(\"-o\",\n",
    "                    \"--output_path\",\n",
    "                    help=\"Path of output TFRecord (.record) file.\", type=str)\n",
    "parser.add_argument(\"-i\",\n",
    "                    \"--image_dir\",\n",
    "                    help=\"Path to the folder where the input image files are stored. \"\n",
    "                         \"Defaults to the same directory as XML_DIR.\",\n",
    "                    type=str, default=None)\n",
    "parser.add_argument(\"-c\",\n",
    "                    \"--csv_path\",\n",
    "                    help=\"Path of output .csv file. If none provided, then no file will be \"\n",
    "                         \"written.\",\n",
    "                    type=str, default=None)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.image_dir is None:\n",
    "    args.image_dir = args.xml_dir\n",
    "\n",
    "label_map = label_map_util.load_labelmap(args.labels_path)\n",
    "label_map_dict = label_map_util.get_label_map_dict(label_map)\n",
    "\n",
    "\n",
    "def xml_to_csv(path):\n",
    "    \"\"\"Iterates through all .xml files (generated by labelImg) in a given directory and combines\n",
    "    them in a single Pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    path : str\n",
    "        The path containing the .xml files\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame\n",
    "        The produced dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    xml_list = []\n",
    "    for xml_file in glob.glob(path + '/*.xml'):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        for member in root.findall('object'):\n",
    "            value = (root.find('filename').text,\n",
    "                     int(root.find('size')[0].text),\n",
    "                     int(root.find('size')[1].text),\n",
    "                     member[0].text,\n",
    "                     int(member[4][0].text),\n",
    "                     int(member[4][1].text),\n",
    "                     int(member[4][2].text),\n",
    "                     int(member[4][3].text)\n",
    "                     )\n",
    "            xml_list.append(value)\n",
    "    column_name = ['filename', 'width', 'height',\n",
    "                   'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    return xml_df\n",
    "\n",
    "\n",
    "def class_text_to_int(row_label):\n",
    "    return label_map_dict[row_label]\n",
    "\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(class_text_to_int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    writer = tf.io.TFRecordWriter(args.output_path)\n",
    "    path = os.path.join(args.image_dir)\n",
    "    examples = xml_to_csv(args.xml_dir)\n",
    "    grouped = split(examples, 'filename')\n",
    "    for group in grouped:\n",
    "        tf_example = create_tf_example(group, path)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "    print('Successfully created the TFRecord file: {}'.format(args.output_path))\n",
    "    if args.csv_path is not None:\n",
    "        examples.to_csv(args.csv_path, index=None)\n",
    "        print('Successfully created the CSV file: {}'.format(args.csv_path))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.compat.v1.app.run()\n",
    "\n",
    "# ---------------------------- 오류 수정 실패 -----------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NdrLX9HRtLkv"
   },
   "source": [
    "# 3. Real Time Detection\n",
    "* Jupyter notebook을 이용하여 openCV 및 Python을 활용한 실시간 감지"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
